{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "485056fd6a5ba2bc7fedfd46b5feccc935a2772f"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "bd6ac6e9684898b75774c0733c56ea9c55c20dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  0.4.1.post2\n",
      "Torchvision Version:  0.2.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "import re\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "import zipfile\n",
    "from torch.optim import lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "b3e06273757cf3cdefe813bf2eb2a6aa937bf86b"
   },
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms \n",
    "#   to the ImageFolder structure\n",
    "data_dir = '../input/bird_dataset/bird_dataset/'\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 20\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 10\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "51f23566bbbce2cc46a909fcf70190342e3e4604"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer,scheduler, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        scheduler.step()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train_images', 'val_images']:\n",
    "            if phase == 'train_images':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device,)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train_images'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train_images':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train_images':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val_images' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val_images':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "1c0cc3b12f19d62f7f22dbef6e4b8461ffa7739a"
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "2c50f13daf12f7a668f92e2c018812560acb2def"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /tmp/.torch/models/resnet152-b121ed2d.pth\n",
      "100%|██████████| 241530880/241530880 [00:19<00:00, 12708222.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (23): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (24): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (25): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (26): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (27): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (28): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (29): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (30): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (31): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (32): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (33): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (34): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (35): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_ft=models.resnet152(pretrained=True)\n",
    "input_size=224\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "35adb5357cdf65aebdc43c7303d1683bc12abd18"
   },
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "Now that we know what the input size must be, we can initialize the data\n",
    "transforms, image datasets, and the dataloaders. Notice, the models were\n",
    "pretrained with the hard-coded normalization values, as described\n",
    "`here <https://pytorch.org/docs/master/torchvision/models.html>`__.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "31cdc606e9b510e20459aa70979bdc9959fbb847"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train_images': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val_images': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train_images', 'val_images']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=0) for x in ['train_images', 'val_images']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2a1a5bf811c18d8a98d0dc538f6df2939e58ae93"
   },
   "source": [
    "Create the Optimizer\n",
    "--------------------\n",
    "\n",
    "Now that the model structure is correct, the final step for finetuning\n",
    "and feature extracting is to create an optimizer that only updates the\n",
    "desired parameters. Recall that after loading the pretrained model, but\n",
    "before reshaping, if ``feature_extract=True`` we manually set all of the\n",
    "parameter’s ``.requires_grad`` attributes to False. Then the\n",
    "reinitialized layer’s parameters have ``.requires_grad=True`` by\n",
    "default. So now we know that *all parameters that have\n",
    ".requires_grad=True should be optimized.* Next, we make a list of such\n",
    "parameters and input this list to the SGD algorithm constructor.\n",
    "\n",
    "To verify this, check out the printed parameters to learn. When\n",
    "finetuning, this list should be long and include all of the model\n",
    "parameters. However, when feature extracting this list should be short\n",
    "and only include the weights and biases of the reshaped layers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "48900061ec6910d02703683f203380b651796adc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "               print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "#optimizer_ft=optim.Adam(params_to_update, lr= 0.01, betas=(0.95, 0.999), eps=1e-03, weight_decay=0.04, amsgrad=False)\n",
    "#optimizer_ft=optim.ASGD(params_to_update, lr=0.01, lambd=0.0001, alpha=0.3, t0=1000000.0, weight_decay=0.04)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98707a947619323422e0e8f13b2e6a30945efae2"
   },
   "source": [
    "Run Training and Validation Step\n",
    "--------------------------------\n",
    "\n",
    "Finally, the last step is to setup the loss for the model, then run the\n",
    "training and validation function for the set number of epochs. Notice,\n",
    "depending on the number of epochs this step may take a while on a CPU.\n",
    "Also, the default learning rate is not optimal for all of the models, so\n",
    "to achieve maximum accuracy it would be necessary to tune for each model\n",
    "separately.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "aac0243f333f98731a39d72e1138035266a2bb69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train_images Loss: 2.8923 Acc: 0.4011\n",
      "val_images Loss: 0.7564 Acc: 0.7573\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train_images Loss: 1.0691 Acc: 0.6913\n",
      "val_images Loss: 0.7416 Acc: 0.7670\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train_images Loss: 0.8490 Acc: 0.7301\n",
      "val_images Loss: 0.6157 Acc: 0.8252\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train_images Loss: 0.8114 Acc: 0.7523\n",
      "val_images Loss: 0.4781 Acc: 0.8155\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train_images Loss: 0.7115 Acc: 0.7837\n",
      "val_images Loss: 0.5807 Acc: 0.7864\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train_images Loss: 0.6100 Acc: 0.8161\n",
      "val_images Loss: 0.5999 Acc: 0.8155\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train_images Loss: 0.5703 Acc: 0.8272\n",
      "val_images Loss: 0.7635 Acc: 0.8155\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train_images Loss: 0.5442 Acc: 0.8253\n",
      "val_images Loss: 0.4759 Acc: 0.8738\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train_images Loss: 0.4666 Acc: 0.8651\n",
      "val_images Loss: 0.4702 Acc: 0.8447\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train_images Loss: 0.4248 Acc: 0.8743\n",
      "val_images Loss: 0.4811 Acc: 0.8447\n",
      "\n",
      "Training complete in 6m 47s\n",
      "Best val Acc: 0.873786\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft,exp_lr_scheduler, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "44ef8755d931bd2e4b68809c9a5408e488ec7827"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/517 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder:\n",
      "    /experiment\n",
      "    /__notebook_source__.ipynb\n",
      "    /.ipynb_checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 517/517 [00:35<00:00, 14.51it/s]\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as Image\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(1)\n",
    "\n",
    "data_transforms1 =  transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "args_experiment = 'experiment'\n",
    "args_outfile = 'experiment/kaggle.csv'\n",
    "args_data = '../input/bird_dataset/bird_dataset/'\n",
    "test_dir = args_data + '/test_images/mistery_category'\n",
    "if not os.path.isdir(args_experiment):\n",
    "    os.makedirs(args_experiment)\n",
    "    \n",
    "print('Folder:')\n",
    "for folder_ in os.listdir():\n",
    "    print('    /' + folder_)\n",
    "    \n",
    "\n",
    "model_ft.eval()\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "from tqdm import tqdm\n",
    "output_file = open(args_outfile, \"w\")\n",
    "output_file.write(\"Id,Category\\n\")\n",
    "X=[]\n",
    "Y=[]\n",
    "for f in tqdm(os.listdir(test_dir)):\n",
    "    if 'jpg' in f:\n",
    "        data = data_transforms1(pil_loader(test_dir + '/' + f))\n",
    "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
    "        if use_cuda:\n",
    "            torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "            data = data.cuda()\n",
    "        X.append(data)\n",
    "        output = model_ft(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        Y.append(pred)\n",
    "        output_file.write(\"%s,%d\\n\" % (f[:-4], pred))\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "84474a09fee1620be8c9a3994d602bfe609d8b25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a download=\"experiment/kaggle.csv\" href=\"data:text/csv;base64,Id,Category
864841d2f9cda02feeaf03acf29407c6,12
efe9c77b5b7b7bebbdb9ae8daf7cc211,8
a09078a10a1de9952263672b5a5d6935,14
0b89974eac5087159b029dc61980510a,10
82677bf899f365fce754816c602fb8db,6
ad08ba64f41b7c50feb7701489a25fc9,10
ee592ccc9591f81961cf05ba2296316c,18
bc5a3f2051ff60264dd535eb97a43b9f,7
f81b5d23407ed54fa3a99ed29fcda1a0,6
de220ee3f8f13956629ebb512391976a,13
5db472b43f5627d4968c40a33278734c,1
42b7c8172fdfbb86e9ed7139d3db3ddd,11
d48d48b4cd9b73ab22fe5803b0b8c89d,15
226cd33fa66e7d7ed28a357e1a3ae3d4,8
046356594366559d408353df3711de5e,10
f32502f507fa358e2129585b6b21bb60,2
cd024f81608ba787e1710652e2057e8c,18
3fdb64bb7f134aed6e5995f879b3bb71,9
b00026ae79cccfff87ea5923a5f2e76c,4
4836bedeec2a2617ee33922ebf89995a,18
0a4a063484eba8522de89bdb24878e74,16
9a7a7125ce4c62052960248b59be470c,5
78906c453cbfeb9647ab0591b7da430f,19
3e619cc5303b8404c8ee5d595f87fb34,0
11d2c1b5a1752c174e66dd49390f36b3,11
56b37b15cfcd97ba9db333ac6d8a8b61,9
817d22ad1bd54ef9311f3cc70083530a,13
68d1869f8a19e3d79cb77ff6fe36ab8d,6
a65445216a669d870645f669ba2438e1,12
ff5bdc3866e4fda1396030b9a146c19d,15
8e0e6ebaf27e74100b27c3e32119b4a7,13
784605d22d28215f13a57e84627fd9a2,11
e7fdcb0c0434c54f7f82c1b3e6ab4999,1
32a10ccf60740ed405e80a85d5c9e2d5,7
27ddf29f30544ee759fcb51ee558c09d,11
25055c9c032445c402baf5e222bfb9e2,1
2773263bb3ff90f9890cd4ac6adb0cca,12
9cc76e9c506161a38e224ae7b4ef4d97,0
574f7b42ff837a315406e6340d0fc54b,1
084479b162adf58c77c4fa906d3f900a,11
f9efa9e2a3226e4c2735542efc63a868,3
44de0bd6c46bcc2adc754188bb6ab142,12
f530b89a6486d5cc8fe20cf1178ff150,5
43830884025146cf1bb483cf35af1fca,0
f5a41d1b7638af9e2f3e1db1622364fd,6
cde3554433d0e297c17c74c9b243f47c,2
dbe9c4f1287fb16ff4658aff9c318d5e,12
5e0604bc219aad1504ff42341334bd34,12
a654571d633f91a8b451ccf979395a19,18
ac372cb67bbd28df50944e4881630142,5
3bf573af80e7c06cbd74978bfa587fb8,9
87dd88ffd7d686e0cde0aec31f66026c,0
654919591aa6028d82cf21c011de2e5f,17
3cff6b88d93b15c1118ddda2892339c6,0
86429297db040c7ce0891aaa774c8b3d,17
4e7f62c679f52732398143afcd3d11a1,6
8bc479269fec2a7eae40385119c2ee49,9
26aaadb293e40df6f135721b3f3637ce,7
21ae3a0177f9e80c91d0c92395b2bd7a,1
423df250254dc327aca81e1903555ec3,9
dfd9f5d2e5ddfe20514f07832bab2602,7
11b8a8e9a432067a19c43ede5b06fa3b,5
c953417f87df9a3d4e1f3be905c26a2c,3
b3ad8445a3ce068343ec95f395cf1d24,4
f6a544074a9b83ccd98bf65a2c3eb57c,9
c5faf9f2c691dbd50566fd0cd4e20276,12
7c18125deb9cddeba47c720635c87533,6
e88979a6b2b8fa4fde40bc89fadb41de,11
cdc8295f4e43d1a69eedb35020489612,0
688b5ba8ac00564557c3febc3055a9df,3
e79f50d3f77b75d5351d814eb47d4d77,18
fd0af389dcb3749670bd1cebd085fb85,9
940402f0b4f0168e8a9172382e0471c9,14
a0f6155272926ff2f81a47ac67333937,8
04c2ed055c16441bc123f341ff172128,19
90a9fb69900186f5aadd53e7790b1cab,1
aaa7e3aaebb5678b56d9d1cd1a616eab,11
aef5fa6068d07e1ae739f35e3166b175,16
b9e87230db892717fdc5a0513e312ccb,14
038872d6dfc340d0ff11f8d3c99d026e,18
2e54c9bac859bc91b0c181c0bacbea92,15
19d7371028e1625fb30cccf0abc56ad6,10
0615e7f6801286210ba978da7a84c3e6,10
770ad07a0ff2092dae44f6ebec9c9886,18
8992398fc52adf23d2549459d92c160c,13
e553a25b8308b91598504b40025112e0,15
111330b5f487ba9a585572e1544f1507,2
e160abb56dc630f27dc5e1d3f41062ce,10
ebc9d3eac76dc9fcd450b312f1feace9,11
54363d1f493ec8774f6d46cadce531cc,10
5234cf2f3c0dd8f92a36394a591c7ce1,11
034abbbb69336b0de7c7c0f2aa1267a6,18
679d31eb7b0f08ba888b20f838084d08,4
de9b0e94e1a74daf9062d84a69fdbba5,11
cc17c00e53ba71456ca41f2ce568e87e,1
def9c02fb41a0ef12cf4835e5fa87bbf,10
1a8bb12e211c86d35ac8105e74e616ee,12
37abcbdb3bca852ee853c48fbd0f2d73,1
a51a4c5800059d2df30e273bafe71175,15
6ba14489a2ada442cd9e511a89f289d9,17
f6eca453d638d5014603cedd9b85c5bc,4
ca0b3b022555260061836d1080e1bad5,10
4091b786289dd16152be4a0e8f455294,11
c543a15f07efc84b5f5030261f0f693c,12
c90c3e687bd51f10c36507f2c0ded63b,0
05c985774004cd0e789e33f2a00ca26a,14
a67d23faf4814a052c423db9b2f28bee,0
1e2903be123e2e0b747943f46d31113d,15
9a50e05daf45aa3a42a088c02957dc6d,12
035f7f6b1a162d86bb4755e6558f33d9,4
20eccc6210f9529e5b0180dd47108881,15
fd5f28cd072603cb6e03c6e011808c0e,5
d1c3426bbca3c249ea0ab1d0caa2e7d6,18
0cf49df5e4eeb368d765c75317298394,8
5a01435acf089e5dfe97eb7865c67b2e,4
c95b3a75971c8aed3695a778c3b36bb6,6
ebe8d00db671bdbb349879a82a3ce490,2
171ad3981fafded4676f5b021377961f,15
c8ec34cf7ee54d51bb632a53d89f5c56,11
8c94b5b5867e8cc67d36629be169f993,18
75f25b0878277c2835885f881f0479f8,1
d8609b1d608b22c597505364414fb917,0
bd278c914f53755282f1d05873c180f3,13
f64eac6ce9235a3b9d2c8a6a8a14ec65,4
948f7030daa5e98b8f183bc7e5507923,10
8367922ad8b74c6047ea82f4d527ce04,13
b5f42249b850a24446a7ff0ef286e487,19
a580c6d4deb63c696640e089b6238ce7,1
c2fa2fd261cbb25a458e16a7e5be6bf9,4
2c74d6d419c534a701d39f7cd5b44c52,19
ae0fba8779fb181a0eb4efc7911e6984,11
b5d6727992a8838847533b791915de2e,4
18783b75d07abcf7c8a77f5bdb28751e,5
9f8a20b1f7342c68de395d82559b2542,14
f5b06a47e3ec141ecc6590a543274f68,4
9b81acdecd60aee4738f9e2fce9d1d37,7
40e9db9adb495ba227987128f4506d87,7
139dd3b6d1034be20cff38318105d08b,7
f341204709b662fdbb4800902cad9df0,13
fb97b3a7197b6f5f856782d39fa14f49,6
383b76214a1bbc1cc8c602c63e479fe1,9
e62dc4014cb2d5283d9667cf8b7ea594,19
310e9b061b6047047c3c503bc978a075,7
0267548c2aac82fe3d7e37ae98b00bd7,18
83a5afccfd69121b1fa338d5f37379a1,18
9ecd953bcb9cdb6baa452aeb374b70fc,11
8a893a972e6eb562e1383f9df0adb777,7
cb7c71c88ac180d44b580813a7167b6d,9
0c0dc45bee119911746c9a77db283873,4
10ad6de262a7bd2aa52abf3f286bd175,13
64302e7bfb63c6665d1f5be6615ff714,1
529cbb5884798ea09c3cb9d5a90aec59,19
506121a04700de37d9484b8902b14224,5
e179ba3451e37f5bd63062b1087dd0a9,10
127efbd89465dc70150d7e440a0d0d1d,5
29b6afd0efda72d10998fbce2c3ccf9f,0
f003abbdf9329f5f631e4c040b9f0d3c,12
64a7a824d6d5c6dba0d881c4505e4240,6
3e127d066d153ab419d86c593f77d629,17
316f7838d482915e1b514c32ade3d5e8,14
85d53b3b764e317c7faacf3221ccc80c,12
100f3192f436325a28debb8d07a5e725,10
67a01e7f879b2427935f0b5d3b0d16a7,2
eb6be750d27e6031a2d03b7c40a6fc94,3
c05f7d929cc67ef267e0ffda404ad0f5,12
9b80d1dfefe4c15256fe0ed20da0f614,1
e49efcb51517beaff3f4f1e631d9d3b7,4
88549604f02092db2d9a4777c7477856,11
14dfa660b37a9ee2712c38f9002d8980,16
07f59eff2e615d4c37658c214cf77996,8
1e8373fa23f94002d192378a39dfb527,0
54fcf8d8ca6a7b6cec5c200f951598f9,13
a2706ca5c2d1e8af4c1698e44987c5ed,1
64f3fa85502e9cff91d6dc88f54be7cb,7
e7929803ee66f3b91f15f7e1e76ca3f6,1
abcc98b6b79b4352afa940f749130013,6
26de142b595665bf7540d0526012608b,13
d9767b49542a15076d1f6971a03df338,16
d3439d774ce2071f95b8809fc52a0515,8
56e4971212cb203c27f24a81ec8e5e7d,19
f8a950b59250dbb8b189a07ad70d85ea,7
3acd266712962940976cbacbeb17a513,0
7c7dda90bde492d9f1b4bd3aa2e8de58,10
71c09173d97cb98fa373913f1e71d966,1
507ac1dc34021ef82d8a91d5347a8ad4,13
15d6c5d42688cbc390e9ba241e93b941,2
501505f4ad95c828a271445f5073a91d,19
baa2c60049e8a78e511faf8e591baac7,6
756abfdacb3a7d798b5ece398bef33e3,9
442c380bbae32987b1f950ab8c488136,2
f4b1b183c44bbad9289b1da4d7896ee7,13
28378d3b2ebdfd18b784559c2334a5c0,3
20e812366b1c572222f1fa1e3d54dc54,3
c2c494a74bfb7ca6c211683b231ccf9c,16
ede49069fad0d28a8cb11d9653cecc14,12
4507ae5207b459e40a261f5a96e29243,12
ffe6dc708419b819ea897d666e986ec6,8
90bf0ec139471e076020fc8aed9b2576,11
2f0b126e2755fffd2c53ba5fc4687a67,1
a52ab6ca2ec1dcd0e4834c50bb69cb3f,18
baa237f0968b7c0b62f951979e6e4053,8
59e088fbdd3688d4f8adf05eed2d1d62,16
99924fde6fd5f81c75e3c0468d9f72a8,1
b2b184e133c5890d48af038f3af513ed,0
2d10d7738ad31d29bdfd45e734ae320f,13
03b5b072b80ec04df1dee668f44abad4,4
c357ca60285c4f965a156c54d15be756,18
88c986cf6e0a2dbee74605d4025cbd8f,3
584fb865fbd41948c0fd3750923b29c3,8
dcd70f3ea711017dae33bdc30445aba0,7
85b096104cfa5ff9bb4bfea171d87208,19
dea9f7b9dfbecd7015d16ab980176e6b,4
365ae0d5dbd27236a807141c5beba78c,5
2698cb89bccf6a5f4b29425f5f573f66,18
0a744c3378ef4ec70f4841e283934103,2
8f05bf8e4f93260959d9bad3ee71bee9,11
17680681fea1cf6df15762035ff09bb8,4
20e309627aaf97e0fee50a39a434c2bf,4
d8fee3d831aea2e61aacd9d429ce4d55,0
8a6da494de49b6897781454488848cf1,18
d4217a56e6a55ae05fc30ae95189f71c,10
0ecc886c88bf3845dce95f2281153b22,0
b89af3dc918af450fbc1c5a4924d2e96,5
2307cf93ce6ab2ab6d91a32ff9f4067b,4
c9c889facf5f109cf1b1fb68ced2a0e1,11
7fbcd92ee0a480ae7675eccbb30a2124,15
bd6b90652602e1b6abe53d991544a1dd,12
b24bc52ab47781ccd5162c9a462741e0,14
87bb8c5543cc059593997ff27601b1f2,10
5f0aef4d606f71aa4f2a540818937de5,11
7e05c5a79f9319f8a8a99548d2f7f954,11
d50158395fdfdedcdd59ab6db5201e99,0
5c1d17bfbf543407b28d6a2f7932410c,18
5c49d532abde454dc109669ae5594916,19
fee2e52c250a812d0e299eb8d0ce558d,15
fb3dac8dd57973515860e1ee184f5f0a,1
75bda85923f3eb3d8338cb2d42339330,9
337494959c5325d7b1f785d41e084f26,18
51075115bd925c20045f9e4e65df914e,14
db67ca52c20e0e15280a38011d4029c2,11
82beb15112d018734c565561bfe231a3,9
0ab685b1515b7d4c76691e8373a65f47,14
d978fd0d4493f87241f805866d1fe5fa,13
be7ed1c27780067717d28964044acf51,1
0247efd7b9d47d036bb4390202a13e69,6
911a1f5affcd2ee7490288765a785281,7
271bf8c2fba59761e340679b3bd8c0eb,11
4dd33eb8e7500905866f3067e11535e4,5
14938f3583bb58e008073772deb9832d,15
27dd99701aa393344c1c15345b319692,16
08edd1314726785f6feddcce7854f881,0
12378a28a80293aa1fc3cda41a7c187b,6
1d901287dd62656c8089234dbb88d732,7
64366faff8ea6c08416a2b6a99e8801e,4
64ea0c5fc9a4085ea5f133d767444a8f,5
59e5a4b2bde751759781096894b0b2af,19
d929573c99d7f45dd0c3f939aaf7dd51,7
c2571a1237f1136dd5a32b67ee0d695f,9
6215a569fc29c911b2798831427aeb62,8
2808c7a907535b23d35c14369b12ca84,17
a0c215cf0e2fcbc8e5d9550bfa1e7882,12
3151f1530e7c0cb6196e494c15eb493b,11
3801cae9487269643906f2125d89d754,19
4e7e72cbf3b0c9259dea6fc6601786b6,19
ac9734b702267d0b1016ae7d41d62928,18
9639dd1d3079304856f3f8ec308deb5b,9
099b8cdf2b51401c0a7b5b43d9e967c0,7
1f5074135fcf27f86c32db0d76fa0453,6
7d034e41ab158f465de70b3270cdb69c,4
81b40058b64df85c845a3936c337c586,0
ceae4443a7365162fe3bea879c4b2776,6
fc2410779646401f73d8d690f6e48f6e,14
f18bbe48a8ebf57958effb02eec3aa7b,12
5414fa19cb93ac5c913b441b1df8fdc0,6
b193593ec3ccc440508145cae0ef086e,16
3d6866a225fc3b20eea604335c7fc28f,7
4ba2d967c5b3f5350ae268556392dfba,15
a795a2f7d04f9959a3ea098c5d1fbcb9,10
23973ce106416044fd4133e2177273fe,10
71a8d323ba672e77c3b86d59f8a279a1,8
4a2fa1c8e573558b1534a1c0802571c7,12
f2870d5dd6b0ee205d960781c0d7d68f,3
cadb9e4da9f48919c21082ab9e948ceb,3
436b2347142a6e5cbc373fdc64836d4a,13
09eb123fe843cf1ae1c14be61f55be37,6
df50119e60bb5673cf07a19c41a8e481,9
b608a78a0a6cf9ff6527e0cc2886cf95,10
e0d5d8f7658e9e7d9cfb33f434a1a36c,7
08f5a56753a26fac59c451aa50d545f4,0
96bc6f12934c2c546ed4d6ddd5dd887c,1
47f6849caa9f6f62464a0c9a6e80d51f,18
e98ecdaa7f147f641b379771920aa004,3
41a4f6b345f3825e3e9087df479184c7,13
f112a4a7936483f41e365309ad44d27a,13
f687ba8db3e512863af57b7281687559,4
21c9ee5b4cfa9ad3e072b8f4d14812b2,18
37f77452e94321c7be2beeb84d381316,8
8939770ea847cce7a6278c5467dc3d87,0
67205b632b48719f20262c8186e675cd,3
e40d7292f81ad017e50b9bd9ad7f4c13,18
222b70d1944b7bb50b41c93962535967,16
27fd211874ea7a6e0e741d0dcfc7b6b7,1
6ff9b514f288e9907b136ba36854a1eb,9
26ebb64db86247606e4f983712d43359,16
7c86b6e08fa21fcf092b402dffcf2117,0
8b26651325df8fb1462dcbb20bf7994d,0
826996758001c20cffd5fb3016a811cf,0
daff1aac7d1ea417939db6e7fc56428e,19
bba3d48d94128d77b9f8a008d383296e,19
724120169552f831a8e17ea8ce8447a4,5
2bad27d8efb4f03863c00c7f573716f0,11
9d7754cd63d0c2ef4114705a37443547,18
99888f22e9e4a17cac0fcf4d39352640,0
e91036d19fbb50e3df6ccf61728abefa,10
6b152adc407f6fcb6e9438cd6cbd6327,10
748b034fbeb69533a9890ce1026b4dcc,8
fe95bce0791a7015500d4b9f1d3d32c9,1
e7833a463fb9af679227107a3c36682c,0
39e68ff4d8328512dfb6a62a19faafab,10
c530c6986170aa1aefe7a930a56ad0db,7
bb6d74478c40198ecc1006daf3d895a3,3
c17c93833fa2b4d56509478c4ca0a98d,2
5aab3de502e7501c9189d17cd0ca928b,12
b9c1ac6d6d2843b496ee0998e4c81595,6
e708d232dc7d3c6234be66455375b916,16
e174e2603923612545b985be528ebeb0,17
43fe3a09f2c7ccd2f97888f341ad20ba,11
51ddc777d64367bbc67e0dbe56621eee,1
045ed95be146d994cfe64be27e1c936a,9
6c70e36afde2a2f31826e21d74c2740d,1
0910f1d5badf42de1aa9bae05037412d,14
958a765e4a60521e1dea9db1f03961e8,11
4be1c9d279c7c7a9e1f8774b6158fb96,15
b41bdb5f6b1464534c3d0575bc3365f8,11
f3ffaa63cce4b75f414d93f65bd45743,1
c3d803d7a201f9bc357c01dc36a4a786,13
a8c9c24429dee5daf87b28661e2ad9eb,19
dbf106cd7622cc0415fd4a0c3131f09d,14
f067618d20c64929543b7a7570f8e629,13
5fa5bfe4f4002b53316e9f29a7ef09e7,8
2efc116c0c094412e79da815696387e4,5
e1aafe2dea8f46187d576ee069434b5e,19
368b4bd2c77a11ea4c2943d048f644f6,12
f76d885e48357b99382078727776ee84,12
f68ddbd9e9b35c5b2778394868577b71,10
49a6cac0897d9cf6459de6e69cc1edbb,19
f7a452821f33c8cd9152fb659ad68213,12
002f61512a368e4c1434eedacf609957,5
46625438b1822c4b527c47bbf579ee4c,19
4d0abdf25ded6709040bb1a9a41edfbe,0
3828cdb69f9ce6a1fad0e65c746f83cd,9
a3a5f7837055db69f10649dd7cf6a92c,18
a3d9980ac0e9517507ffedb37779895a,9
d0b65a2c991c70f6000bae1efe30c27b,4
d5915b969c77177c90c6f2f6748c17d6,12
125f6d101a92e7a7eabb2a45fe233f34,0
bc92e79bfbf1434963f1364ffbda7dec,18
6ad5bf7135e35a3ed5d3f34013024a1f,2
6b07f85c04e8485623ee984d132c7a79,18
f4330d0d109de59e306824bd55628742,19
3deb505285161e32927fc0bc3b7da8cd,7
3b567146f9148617c5fbed9b346e5bb1,15
de690e9504ff0f1c63eb9381defd0390,12
b5b4274be0ac2d31944346addb3dfdab,18
964581a80041d2f57c4dd40a82ad94dd,19
fa3db38c68c70898714a17ca83774158,19
374c619f727583cb75563891f6b855ee,13
a90097b8ebc1a7ffd5eecf31fd9560ce,0
b5316c8e51b97debf6420b34325ec114,10
73bf9a74144b55e6e716add70398ebf5,2
1f18abbf61f6377ef26100fc26edeedc,0
d011945315676022fa420f46a4750842,12
5ea2538b1c3de10033672caf79a13074,19
debdd05c4a5cfc1ea008e040ca64fc30,14
ce1028221704ba6e933f4269faad92ed,18
b77bedbe9c27d1983d1151c7dd17c7e0,4
872aeb779216b09b04eb15dba20afe3e,5
866f2c4a13bcd4f399202301cf72ff72,4
5e0890d770f76292620c958c713ba86a,11
442a1034a34bcb93e8a49cd1a68fccdb,7
98e0764fa15ffea4277ef27c3bd9e581,9
6e2110dd12136a681b2dd32fff190e90,0
66b4e2665ab671f2dced94770475659c,6
ed87bec047ced0823db1c3d4065ba1f0,0
1b62fffcbf47a4f9e32b400edc662f1f,4
1e214cfa62f74928d7ea5d5c5c35ca93,15
dea78880b447d7db1d776b2045b6f036,6
96661ef2172a349dc017b771e01d141e,14
61f6255e139b2091d32fd21e20ddaa36,1
51972b83934d272b99a9d14fb1febc08,6
a39fbf09023d2b98cbd486ec3a244765,1
b40be7f30a4a196d5fad13d01a4f51b8,4
439c8e6adb72aebff8ddff6700d90730,3
f11ec871f7ebefe5731d487b6a7854cc,13
4844a713043c515f66a97dc3b319ad65,7
d97a794bc6e951b13891873045115174,10
ba03abd3b6c6c044eb944730ed271e8b,5
6acc98722be2e78bd70aa84f648fd0e5,13
4d6af158889147d8cc51315b59831197,7
42c8cb49c2f0f6b74e04d1566678b19c,1
6ebdc52674fa9872a716060f4353b6fb,4
e30e4f62cc4f88968ddf35e9624e48fe,18
8c7757543b9a3245b4fa95b789392caf,11
e51ad12ab2a8fe2cb645c92964c7df8f,4
7fa62c3810e0689e3661bd381c944beb,7
77059b120dae3d33712322af77fb2c9c,1
6e3c2c583774606210735e93fda8a521,12
a131752592bf0ff25acd37c22e8dc40b,11
b936a98be5409db37f27bac20bee4ddd,17
a05ed5dd6cbd3097e81e3c76ac690465,0
2c47c51d1538b82eb31a2f6a66e4b340,16
45abe39f83c9f5e0d7c1fe5162e655d6,9
8c5b5c02769e3e1788fdaf8d27ec4a0a,5
3dadf8d0037d2a1f40999c9da306b03a,7
da9aa4eaae3ec62de9195ae742dcf2ad,14
61e61ec16868b8972f02fb6fcf4c6ce7,19
5526ea87142b4a88ee4eb2803e2b9bdf,5
46f7fd4c992bc2162b87b9ccc08c777b,4
9d4bc0dc9daee3a8d0baecf4d2365c4f,7
409916784b3e672d1702b39fa50cf013,17
791311892ce625d16d32786c2679cb88,12
c838e8090064966e460265057091f3d1,14
0676b04fc9527343bee8ae5a2a9d4692,0
eac387ffc0e152a5d2934e95ba7a3097,7
a34d33333c18da1258e790c60f2b07a2,11
d2ad2845327eaa0a6c14736820256086,0
f797dafedeabc2cd79aa730d029bd09b,19
57e0aecd931044c03adde0ff6e944b4c,13
ce85bf0371009d7b98cbd0828726b35a,9
703315c52c662c32732bed3a90925817,8
371e69a08d83234cc16e353734885d26,6
8970716e0bdf666242dade373592439f,18
bc27f534edd690cffdb07f3b314c44c3,14
7e07e19a08c1630ac4d556e7412a31fc,9
d716f3a09d7a8efa0ccac70d81b3b503,6
ced6cfcd03794991fa5145f7f03675fa,10
90dab576ce9a913ef8faced7adf48b4f,16
9de9a598bc6e0248ac4337b212fac452,18
030c7d18b20ee586db3b74d9966c0348,18
e608121a156b31be8799d2d640cfac8c,11
99a8b2b93391f72f4437c4bf4465501e,12
5bf1d328b7f5cd9f0c6fdfc8fe8a5c23,10
b8e4200b831bbd37bfff150418c4c29b,10
65f3d67b186fd22b5c0e84b2df63f10c,9
70fddb3c64b44a4d43e32a7c8148c425,18
f9004ef97c205c58637c053d69f8ed41,2
93f36cd6408982bf02078577ec224014,14
176e2ea6dbe51d098aa87adaacae6fd8,0
ecca20075dc30f33bd55b681a9488f1d,19
3e353362a5220111748db43b03ef7551,3
e03a8b03c1edb34b1f31b56b386a6101,8
16f3532d0c649270ba1b6ee6a2a991d1,4
532bdf3560359a3be1988d9e68bd39b1,18
f02d6db37917adaf898f4af0362f1bb2,11
0b7b64c3eeae20e8f71923914a8643ef,1
105a949eb4533e569f8fb6fdf220ff7f,17
493f81135b862db618be038a740031b5,8
31e7782137785c3f93d141c4f1ae4a36,0
769f399ad73cd5c4983a4a42be8ef2d6,4
09908286566fd3824e2db5d7fb2826b5,6
7dfe6c7a6d93ea21c0b715fca04c63ed,19
9d8264c3393f849298c0642add7f00ea,10
e1815436e1aa4c04fb4d853df0a22d17,9
39a3b1946cd7a7bb89834beb4828cbba,13
5c42c351dcc9d6f372d17b39b6a27860,4
cb0ee3db495366b1bac47eecfb07fc26,10
465ce159f0171470a282655d369bdc53,17
d18c1c9b2849e5f77c2bc250635f0d95,9
1d46afe83c6d66741ec950843307f6e6,15
2507bf470255a2d6de414439a980855c,9
06a0cec19b33162bb0f24416107540fc,14
4edeccbcc5541a233750653b27177f13,0
130189af6e37c7d4620cc67dcab79699,5
b50e2e902b001cb003bc970189432426,11
a59dd8f627b26d7347a40dd2bf45b8ff,12
f540d62813721058081c65c41a9cb0dc,11
eeb391e30d46f5f2cfe4108c7a251ee9,11
3091bb2374374f0ed34faed50815ae12,3
8ede0bc5a4976385dcfe6e38feaf90c2,14
28375cb44f99643a7d8898b3d6efa20f,9
57cdd6f0a11c02e93b41d636bcaf04a4,5
55d965bd3cc40f82d8eca35d2cf7a04e,0
4ac18803f100031f5f87c1b78d62049c,3
971d707b8686c641fc40972a74186879,4
fef53a1dada4a77de35c609180d41936,2
bbe0a4e68ded4b91ac7f5b19d811e0ec,11
f0fd665607c8b4c18ccbdebdd3d1931e,5
518b04e5ff71aa69c32c72a7cf1bbff6,6
97a9bdf7f7c32a8b07d4dfbd288bc2d0,18
b4b2bb2d96768ef960b53ffc3b3e7d1b,4
ca4b49237d0803abbb845d6d3d515ad5,0
234e89833f23f32bed44a3b314cbf786,12
46a1fe86e0f64c627a2031610afff5e5,15
8a94c643402bd103bb29e4ad2c7f4e78,6
6357498ff675b57ed4d100d83a2c1469,18
5ff7046848770cd6a7847b477fb59c20,5
b6093337ef2a45c4366995b2874ca554,9
f4031c2fc6342ef8b328538d26782e0b,3
77703b27dc560baa58cfb3c714f577e6,0
4153266b2a167958f6ef872b8a13317f,15
746e9072f9d600f848ad9983de373804,10
97b9e4f0054330bf0f33e56a80f3b5a7,9
31a725674a21f85f1d79cf1236bf5e67,4
7dcf5624066b67a29f423a8071fcd984,15
502e97f2577d5f29e6b86752400fb0c4,17
6edea463a50c585a838dd6608cc0e03b,12
639d6384a2c426f01597d1a668d571a7,17
4d37a50935575d523103250da65cc5e8,2
81ab4c4e6a6f0c15464e157b4db7638a,10
800d15192f06a35458fd0c5d64ef59b5,1
896807af0f5df0d664e003daa58fdf74,12
f093b8d142b73f532ea6869f13edcb2e,3
f647602f147dce978d4a01019f88e4d2,7
d08b43687503170c36402386df6a490f,1
8064ad6e67047772008ef4320d1515d4,16
80603199e49605b8db742df76e7cb418,4
e13d37bfdad34e200755cffa193366e8,19
\" target=\"_blank\">Download CSV file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "def create_download_link(title=\"Download CSV file\", filename=\"experiment/kaggle.csv\"):\n",
    "    df = pd.read_csv(filename)\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc0322ae00b8077e7efb54a5456e9ef96ecc3d20"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d55e15887fd94b00fdad6f624f8cc86cff6cf55"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
